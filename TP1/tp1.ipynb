{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Trabalho Prático 1 - Daniel Pimentel Kansaon</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trabalho consiste na aplicação de algoritmos supervisionados comparando ao todo 6 métodos:\n",
    "\n",
    "- **Naive Bayes**: Apenas um experimento para servir de baseline.\n",
    "- **Decision Tree**: Variar a altura máxima da árvore (incluindo permitir altura ilimitada) e mostrar os resultados graficamente.\n",
    "- **SVM**: Avaliar os kernels linear, sigmoid, polinomial e RBF.\n",
    "- **k-NN**: Variar o número k de vizinhos e mostrar os resultados graficamente.\n",
    "- **Random Forest**: Variar o número de árvores e mostrar os resultados graficamente.\n",
    "- **Gradient Tree Boosting**: Variar o número de itera¸c˜oes e mostrar os resultados graficamente.\n",
    "\n",
    "Os métodos serão testados em um problema de classificação binária (0 - 1) de candidatos a exoplanetas encontrados pela sonda espacial Kepler da NASA. Um exoplaneta é um planeta fora do sistema solar (i.e. que não orbita o sol). A sonda primeiro identifica sinais de possíıveis exoplanetas, chamados de Kepler Object of Interest (KOI). Porem nem todos os KOIs são de fato exoplanetas, alguns se tratam de \"Falsos Positivos\" de origens diversas. A tarefa é então classificar os KOIs entre exoplanetas\n",
    "confirmados e \"Falsos Positivos\". Cada observação corresponde a um KOI e as features são características estimadas de cada (possível) exoplaneta (tamanho, temperatura, features da estrela hospedeira, etc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando as referencias que serão usadas durante o trabalho\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import feature_selection\n",
    "import statistics\n",
    "\n",
    "#Metodos\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors #K-nn\n",
    "from sklearn import ensemble #Random Forest\n",
    "from sklearn.naive_bayes import GaussianNB #Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As constantes do projeto estão adicionadas aqui.\n",
    "\n",
    "# Caminho arquivo com os dados\n",
    "FILE_PATH = \"koi_data.csv\"\n",
    "\n",
    "#Tamanho do fold que será utilizado para a etapa de Cross-Validation\n",
    "K_FOLD = 5\n",
    "\n",
    "#Coluna TARGET do arquivo CSV\n",
    "TARGET = \"koi_disposition\"\n",
    "\n",
    "#Coluna que possui o nome do KOI\n",
    "COLUMN_KOI = \"kepoi_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento nos Dados\n",
    "\n",
    "Como dito acima, cada observação realizada corresponde a um KOI e as features são características estimadas de cada (possível) exoplaneta (tamanho, temperatura, features da estrela hospedeira, etc).\n",
    "\n",
    "Assim, nesta etapa serão realizados processamentos nos dados a fim de prepará-los para a execução dos algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas: 5202\n",
      "Numero de colunas: 43\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Imprime algumas informacoes basicas sobre os dados\n",
    "print(\"Numero de linhas: {}\".format(df.shape[0]))\n",
    "print(\"Numero de colunas: {}\".format(df.shape[1]))\n",
    "\n",
    "# Cria a lista de features com base nas colunas do arquivo CSV\n",
    "features = list(df.columns)\n",
    "\n",
    "#Remove a coluna target pois ela que está querendo prever.\n",
    "features.remove(TARGET)\n",
    "\n",
    "#Remove a coluna de nome, pois não é necessária para a predição\n",
    "features.remove(COLUMN_KOI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando o Target (rótulos dos dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FALSE POSITIVE</th>\n",
       "      <th>CONFIRMED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>koi_disposition (%)</th>\n",
       "      <td>59.55</td>\n",
       "      <td>40.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FALSE POSITIVE  CONFIRMED\n",
       "koi_disposition (%)           59.55      40.45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Porcentagem de False Positive e Confirmed \n",
    "display((df[TARGET].value_counts()/len(df)*100).round(2).to_frame(TARGET +\" (%)\").T)\n",
    "\n",
    "df[TARGET] = (df[TARGET] == \"CONFIRMED\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados para a validação cruzada\n",
    "\n",
    "Nessa parte são separados os dados com base nos folds(5) para a validação cruzada. A partir disto, os algoritmos irão usar essa separação para os testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando os vetores de treino e teste\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "\n",
    "#Selecionando as features\n",
    "#df = df.sample(20000, replace=False, random_state=1)\n",
    "skb = feature_selection.SelectKBest(feature_selection.f_classif, 41)\n",
    "skb = skb.fit(df[features], df[TARGET])\n",
    "\n",
    "#separa o X são os exemplos e o Y é o rótulo [0 ou 1]\n",
    "X = df\n",
    "Y = df[TARGET]\n",
    "\n",
    "#Aqui é realizado é feito a separação dos dados em K_FOLD = 5.\n",
    "data_kfold = StratifiedKFold(n_splits=K_FOLD)\n",
    "data_kfold.get_n_splits(X, Y)\n",
    "\n",
    "\n",
    "#Nessa parte é lido os folds e armazenado nas listas.\n",
    "# Exemplo: x_train [ fold1, fold2, fold3, fold4, fold5 ]\n",
    "\n",
    "for train_index, test_index in data_kfold.split(X, Y):\n",
    "    x_train.append(skb.transform(df.loc[train_index, features]))\n",
    "    x_validation.append(skb.transform(df.loc[test_index, features]))\n",
    "    y_train.append(df.loc[train_index, TARGET])\n",
    "    y_validation.append(df.loc[test_index, TARGET])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_naivebayes():\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    \n",
    "    for i in range(0, K_FOLD):            \n",
    "        gnb = gnb.fit(x_train[i], y_train[i]) #Treino\n",
    "        train_acc.append(gnb.score(x_train[i], y_train[i]))\n",
    "        val_acc.append(gnb.score(x_validation[i], y_validation[i]))   \n",
    "          \n",
    "    print(\"Média da Acurácia na treino: {:.3}\".format(np.average(train_acc)))\n",
    "    print(\"Média da Acurácia na validação: {:.3}\".format(np.average(val_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na treino: {:.3}\".format(statistics.stdev(train_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na validação: {:.3}\".format(statistics.stdev(val_acc))) \n",
    "    \n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Média da Acurácia na treino: 0.8\n",
      "Média da Acurácia na validação: 0.803\n",
      "Desvio Padrão da Acurácia na treino: 0.0118\n",
      "Desvio Padrão da Acurácia na validação: 0.0514\n"
     ]
    }
   ],
   "source": [
    "executar_naivebayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_k_nn(k): \n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    print(\"K = {}\".format(k))             \n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k) \n",
    "    \n",
    "    for i in range(0, K_FOLD):          \n",
    "        clf = clf.fit(x_train[i], y_train[i])  \n",
    "        train_acc.append(clf.score(x_train[i], y_train[i]))\n",
    "        val_acc.append(clf.score(x_validation[i], y_validation[i]))\n",
    "\n",
    "    print(\"Média da Acurácia na treino: {:.3}\".format(np.average(train_acc)))\n",
    "    print(\"Média da Acurácia na validação: {:.3}\".format(np.average(val_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na treino: {:.3}\".format(statistics.stdev(train_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na validação: {:.3}\".format(statistics.stdev(val_acc)))   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 5\n",
      "Média da Acurácia na treino: 0.848\n",
      "Média da Acurácia na validação: 0.773\n",
      "Desvio Padrão da Acurácia na treino: 0.00781\n",
      "Desvio Padrão da Acurácia na validação: 0.0482\n"
     ]
    }
   ],
   "source": [
    "executar_k_nn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 10\n",
      "Média da Acurácia na treino: 0.825\n",
      "Média da Acurácia na validação: 0.776\n",
      "Desvio Padrão da Acurácia na treino: 0.0109\n",
      "Desvio Padrão da Acurácia na validação: 0.0456\n"
     ]
    }
   ],
   "source": [
    "executar_k_nn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 32\n",
      "Média da Acurácia na treino: 0.799\n",
      "Média da Acurácia na validação: 0.781\n",
      "Desvio Padrão da Acurácia na treino: 0.011\n",
      "Desvio Padrão da Acurácia na validação: 0.0539\n"
     ]
    }
   ],
   "source": [
    "executar_k_nn(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_svm_linar(c):    \n",
    "    clf = svm.SVC(c, \"linear\")\n",
    "    \n",
    "    for i in range(0, 1):          \n",
    "        clf = clf.fit(x_train[i], y_train[i])  \n",
    "        train_acc.append(clf.score(x_train[i], y_train[i]))\n",
    "        val_acc.append(clf.score(x_validation[i], y_validation[i]))\n",
    "   \n",
    "    print(\"Média da Acurácia na treino: {:.3}\".format(np.average(train_acc)))\n",
    "    print(\"Média da Acurácia na validação: {:.3}\".format(np.average(val_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na treino: {:.3}\".format(statistics.stdev(train_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na validação: {:.3}\".format(statistics.stdev(val_acc)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executar_svm_linar(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_ramdomforest(N, max_depth):\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=N, max_depth=max_depth)\n",
    "    \n",
    "    for i in range(0, K_FOLD):          \n",
    "        clf = clf.fit(x_train[i], y_train[i])  \n",
    "        train_acc.append(clf.score(x_train[i], y_train[i]))\n",
    "        val_acc.append(clf.score(x_validation[i], y_validation[i]))        \n",
    "\n",
    "    print(\"Média da Acurácia na treino: {:.3}\".format(np.average(train_acc)))\n",
    "    print(\"Média da Acurácia na validação: {:.3}\".format(np.average(val_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na treino: {:.3}\".format(statistics.stdev(train_acc)))\n",
    "    print(\"Desvio Padrão da Acurácia na validação: {:.3}\".format(statistics.stdev(val_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média da Acurácia na treino: 1.0\n",
      "Média da Acurácia na validação: 0.966\n",
      "Desvio Padrão da Acurácia na treino: 0.000107\n",
      "Desvio Padrão da Acurácia na validação: 0.0133\n"
     ]
    }
   ],
   "source": [
    "executar_ramdomforest(50, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média da Acurácia na treino: 0.991\n",
      "Média da Acurácia na validação: 0.965\n",
      "Desvio Padrão da Acurácia na treino: 0.00192\n",
      "Desvio Padrão da Acurácia na validação: 0.0131\n"
     ]
    }
   ],
   "source": [
    "executar_ramdomforest(25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
